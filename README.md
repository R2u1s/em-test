# Тестовое задание. Руслан Буданов

В корне три папки, в каждой - проект одного из сервисов. Два сервиса в соответствии с первым заданием и один сервис в рамках второго задания.
Также в архиве backup файл базы данных PostgreSQL. База данных одна для всех трех сервисов. 

Для запуска каждого из сервисов - команда npm run start (предварительно npm i)
Первый и второй сервис запускаются на 3000 и 3001 порту. Третий сервис - 3000.

## Первый сервис имеет следующие эндпоинты:
* get, '/products' - получение записей продуктов (plu, name)
Также здесь возможно использование фильтров - name, plu, prefix. Первый - фильтр по имени, второй по артикулу plu, третий - по первой цифре пятизначного артикула plu. 
Пример запроса: http://localhost:3000/products?name=бананы&prefix=9
* post, '/products/create' - создание продукта. В теле запроса необходимо передать plu и name
* get, '/stock' – получение записей остатков на полке (plu, shop_id, qty)
Также здесь возможно использование фильтров:
- shop_id – по идентификатору магазина
- plu – по артикулу 
- prefix – по первой цифре пятизначного артикула plu
- from – количество «от»
- to – количество «до»
* patch, '/stock/increase' – увеличение количества товара на полке магазина. Нужно передать в теле запроса plu, shop_id, amount
* patch, '/stock/decrease' – уменьшение количества товара на полке магазина. Нужно передать в теле запроса plu, shop_id, amount
* post, '/products/create' – создание остатка на полке. В теле запроса необходимо передать plu, shop_id, qty (количество)
* get, '/orders' – получение записей остатков в заказах (id, plu, shop_id, qty)
Также здесь возможно использование фильтров:
- shop_id – по идентификатору магазина
- plu – по артикулу 
- prefix – по первой цифре пятизначного артикула plu
- from – количество «от»
- to – количество «до»
* patch, '/orders/increase' – увеличение количества товара в заказе. Нужно передать в теле запроса id, amount
* patch, '/orders/decrease' – уменьшение количества товара в заказе. Нужно передать в теле запроса id, amount
* post, '/orders/create' – создание остатка на полке. В теле запроса необходимо передать plu, shop_id, qty (количество)
Второй сервис имеет следующие эндпоинты:
* post, '/' – создание записи изменения. В теле запроса необходимо передать action – строковое значение, обозначающее тип действия (например, `INSERT`), change – объект, содержащий всю необходимую информацию об изменении, здесь необходимо передать plu и shop_id для корректной работы фильтров. 
* get, '/' – получение записей изменений. Здесь возможно использование фильтров:
- shop_id – по идентификатору магазина
- plu – по артикулу 
- prefix – по первой цифре пятизначного артикула plu
- action – тип действия
- from – дата «от»
- to – дата «до»
Также передаются параметры пагинации: количество отображаемых элементов – pagination, и страница – page.
Пример запроса: 
http://localhost:3001?from=2024-09-14&to=2024-09-15&pagination=3&page=1

Взаимодействие сервисов реализовано c помощью HTTP API запросов. Возможно в реальных условиях это будет не эффективно, и если, к примеру, стоит требование организовать подгрузку изменений в условиях реального времени, тогда можно использовать WebSocket, особенно это актуально, если нужно будет видеть создаваемые заказы. С этой технологией знаком.
Возможно, в случае большого количества сообщений об изменениях для эффективности и надежности сервиса следует использовать очереди сообщений. Слышал, что для этого используется, к примеру, платформа Kafka. Но сам пока не пробовал реализовывать. Думаю здесь нужно смотреть в зависимости от ситуации и мне сложно на данном этапе предугадать, какие сложности могут возникнуть.

## Сервис 2 задания
Здесь есть один эндпоинт:
* patch, '/users/:id' – прописывает в поле problem значение false и выдает количество пользователей, которые имели true в этом флаге.
Вижу, что в задаче нужно было попробовать создать большое количество пользователей в БД – более 1 млн. Понимаю, что тут встает вопрос эффективности работы сервиса. В данном случае не увидел паузы при обработке запроса, поэтому не стал ничего добавлять. 
Как вариант оптимизации запроса, вижу использование кэширования, поскольку от запроса к запросу будут обрабатываться одни и те же значения записей. Особенно актуально, если такой запрос будет делаться часто. Для добавления кэширования можно использовать Redis. 
